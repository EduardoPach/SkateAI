{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import yaml\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from models import ResNet18_RNN\n",
    "from dataset import TricksDataset\n",
    "from utils import train_fn, get_loaders, load_checkpoint, save_checkpoint, check_performance, plot_frames\n",
    "\n",
    "with open(\"config_hard.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "EPOCHS = config[\"training_parameters\"][\"epochs\"]\n",
    "LEARNING_RATE = config[\"training_parameters\"][\"learning_rate\"]\n",
    "LABEL_COLUMNS = config[\"training_parameters\"][\"label_columns\"]\n",
    "\n",
    "TRAIN_CSV = config[\"dataloader_parameters\"][\"train_csv\"]\n",
    "VAL_CSV = config[\"dataloader_parameters\"][\"val_csv\"]\n",
    "ROOT_DIR = config[\"dataloader_parameters\"][\"root_dir\"]\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 2\n",
    "MAX_FRAMES = config[\"dataloader_parameters\"][\"max_frames\"]\n",
    "NUM_WORKERS = config[\"dataloader_parameters\"][\"num_workers\"]\n",
    "PIN_MEMORY = config[\"dataloader_parameters\"][\"pin_memory\"]\n",
    "\n",
    "RNN_TYPE = config[\"model_parameters\"][\"rnn_type\"]\n",
    "RNN_LAYERS = config[\"model_parameters\"][\"rnn_layers\"]\n",
    "RNN_HIDDEN = config[\"model_parameters\"][\"rnn_hidden\"]\n",
    "TRAINABLE_BACKBONE = config[\"model_parameters\"][\"trainable_backbone\"]\n",
    "HEADS_PARAMS = config[\"model_parameters\"][\"heads_params\"]\n",
    "HEADS_PARAMS[\"in_features\"] = RNN_HIDDEN * MAX_FRAMES\n",
    "train_labels = pd.read_csv(TRAIN_CSV)\n",
    "df_train = train_labels.loc[train_labels[\"trick_name\"].isin([\"heelflip\", \"kickflip\"])].reset_index(drop=True).copy()\n",
    "if \"trick_name\" in LABEL_COLUMNS:\n",
    "    HEADS_PARAMS[\"n_tricks\"] = df_train[\"trick_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18_RNN(\n",
    "    RNN_TYPE, \n",
    "    RNN_LAYERS, \n",
    "    RNN_HIDDEN, \n",
    "    HEADS_PARAMS, \n",
    "    TRAINABLE_BACKBONE\n",
    ")\n",
    "\n",
    "resnet_transforms = resnet.ResNet18_Weights.DEFAULT.transforms()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loss_fns = {\n",
    "    'trick_name': nn.CrossEntropyLoss(),\n",
    "    'landed': nn.CrossEntropyLoss(),\n",
    "    'stance': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    resnet_transforms,\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    resnet_transforms,\n",
    "])\n",
    "\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1, dtype=int).set_output(transform=\"pandas\")\n",
    "encoder.fit(df_train[LABEL_COLUMNS])\n",
    "\n",
    "train_ds = TricksDataset(\n",
    "    csv_file=df_train,\n",
    "    root_dir=ROOT_DIR,\n",
    "    max_frames=MAX_FRAMES,\n",
    "    transform=train_transforms,\n",
    "    label_enconder=encoder\n",
    ")\n",
    "\n",
    "train_loader, val_loader = get_loaders(\n",
    "    df_train,\n",
    "    VAL_CSV,\n",
    "    ROOT_DIR,\n",
    "    MAX_FRAMES,\n",
    "    1,\n",
    "    train_transforms,\n",
    "    val_transforms,\n",
    "    NUM_WORKERS,\n",
    "    PIN_MEMORY,\n",
    "    encoder\n",
    ")\n",
    "\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [05:01<00:00,  4.79s/it, loss_total=2.23]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    x = train_fn(train_loader, model, optimizer, loss_fns, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "PREDICTION #1: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' True 'fakie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #2: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['heelflip' False 'fakie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #3: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['heelflip' True 'nollie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #4: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' True 'fakie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #5: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' True 'regular']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #6: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' True 'nollie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #7: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' True 'nollie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #8: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['heelflip' True 'nollie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #9: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' False 'fakie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #10: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' True 'fakie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #11: \n",
      " Prediction: [['kickflip' True 'fakie']] \t\t Groundtruth: [['kickflip' True 'nollie']]\n",
      "--------------------------------------------------\n",
      "PREDICTION #12: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPREDICTION #\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     preds \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m      7\u001b[0m pred_decoded \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minverse_transform(np\u001b[39m.\u001b[39marray([[F\u001b[39m.\u001b[39msoftmax(val)\u001b[39m.\u001b[39margmax()\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m preds\u001b[39m.\u001b[39mitems()]]))\n\u001b[1;32m      8\u001b[0m target_decoded \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39minverse_transform(np\u001b[39m.\u001b[39marray([[val\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m target\u001b[39m.\u001b[39mitems()]]))\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Projects/SkateAI/models/models.py:30\u001b[0m, in \u001b[0;36mResNet18_RNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m B, F, C, H, W \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape \u001b[39m# Batch x Frames x Channels x Height x Width \u001b[39;00m\n\u001b[1;32m     29\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, C, H, W) \u001b[39m# Reshaping to B*F x C x H x W\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasemodel(x) \u001b[39m# Extracting Features\u001b[39;00m\n\u001b[1;32m     31\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(B, F, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# Reshaping to B x F x Features (ResNet18 outputs B*F x 512)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(x) \u001b[39m# output, hidden and cell states\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torchvision/models/resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 276\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    279\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[1;32m     97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/SkateAI/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for idx, (data, target) in enumerate(train_loader):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"PREDICTION #{idx+1}: \")\n",
    "    with torch.no_grad():\n",
    "        preds = model(data)\n",
    "    pred_decoded = encoder.inverse_transform(np.array([[F.softmax(val).argmax().item() for key, val in preds.items()]]))\n",
    "    target_decoded = encoder.inverse_transform(np.array([[val.item() for key, val in target.items()]]))\n",
    "    print(f\" Prediction: {pred_decoded} \\t\\t Groundtruth: {target_decoded}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SkateAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e54162d8ffe848d1db2f4e0bfb1e0101e9815fb34abe5a4effde74cfd4be5d19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
